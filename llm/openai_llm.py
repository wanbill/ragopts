from .base_llm import BaseLLM
from typing import Dict, Any, Generator, List
from openai import OpenAI
from openai.types.chat.chat_completion import ChatCompletionMessage
from pydantic import BaseModel

class FunctionCall(BaseModel):
    arguments: str
    """
    The arguments to call the function with, as generated by the model in JSON
    format. Note that the model does not always generate valid JSON, and may
    hallucinate parameters not defined by your function schema. Validate the
    arguments in your code before calling your function.
    """

    name: str



class OpenAILLM(BaseLLM):
    def __init__(self, default_config: Dict[str, Any], client_config: Dict[str, Any]) -> None:
        super().__init__()
        self.default_config = default_config or dict(model="gpt-3.5-turbo")
        self.client = OpenAI(**client_config)
        

    def completion(self, *args, **kwargs) -> ChatCompletionMessage:
        self.default_config.update(kwargs)
        resp = self.client.chat.completions.create(
            *args,
            **self.default_config
        )
        return resp.choices[0].message
    
    def stream(self, history: List[Dict[str, str]], *args, **kwargs) -> Generator:
        self.default_config.update(kwargs)
        self.default_config['stream'] = True
        stream = self.client.chat.completions.create(
            *args,
            **self.default_config
        )
        ans = None
        for i, chunk in enumerate(stream):
            # print(chunk.choices[0])
            if i == 0:
                if (func := chunk.choices[0].delta.function_call):
                    ans = FunctionCall(name=func.name, arguments="")
                    tmp = func.name
                else:
                    ans = chunk.choices[0].delta.content
                    tmp = ans
            else:
                if isinstance(ans, str):
                    ans += (tmp := chunk.choices[0].delta.content or "")
                elif chunk.choices[0].delta.function_call:
                    ans.arguments += (tmp := chunk.choices[0].delta.function_call.arguments)
            if isinstance(ans, str):
                history[-1] = ChatCompletionMessage(content=ans, role="assistant")
            else:
                history[-1] = ChatCompletionMessage(function_call=ans, role="assistant")
            yield tmp
